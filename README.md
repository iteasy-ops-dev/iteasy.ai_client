# ITEasy AI Client

**ITEasy 사내 전용 AI 채팅 인터페이스**

ITEasy 팀원들을 위한 전용 AI 채팅 클라이언트입니다. 업무 효율성을 높이고 빠른 AI 상담이 가능하도록 설계된 현대적인 웹 인터페이스를 제공합니다.

- **대상**: ITEasy 사내 구성원
- **목적**: 업무 지원 및 생산성 향상을 위한 AI 어시스턴트
- **기술**: React, Next.js 14, Server-Sent Events (SSE)를 활용한 실시간 스트리밍

**개발**: [iteasy-ops-dev](https://github.com/iteasy-ops-dev) (iteasy.ops.dev@gmail.com)

## 주요 기능

### 💼 업무 지원 기능
- 🚀 **실시간 스트리밍**: SSE를 활용한 즉시 응답
- 💬 **다중 대화 세션**: 프로젝트별/주제별 대화 관리
- 📊 **토큰 사용량 추적**: 비용 관리 및 사용량 모니터링
- ✏️ **대화 제목 편집**: 업무별 대화 정리 및 분류

### 🔧 설정 및 관리
- 🔑 **API 키 설정**: 사내 OpenAI API 키 동적 구성
- ⚙️ **AI 모델 설정**: GPT 모델, 창의성, 응답 길이 조절
- 🔍 **API 키 검증**: 실시간 유효성 확인
- 💾 **대화 저장**: 로컬 스토리지를 통한 대화 기록 보존

### 🎨 사용자 경험
- 📱 **반응형 디자인**: 데스크탑/모바일 모든 환경 지원
- 📝 **마크다운 렌더링**: 코드 블록, 표, 목록 등 완벽 지원
- 🎨 **모던 UI**: 직관적인 메신저 스타일 인터페이스
- 🛡️ **오류 처리**: 사용자 친화적 에러 메시지

## Tech Stack

- **Framework**: Next.js 14 with App Router
- **Language**: TypeScript
- **Styling**: Tailwind CSS
- **AI SDK**: Vercel AI SDK (@ai-sdk/openai)
- **State Management**: Zustand
- **Markdown**: react-markdown + remark-gfm
- **Code Highlighting**: react-syntax-highlighter
- **Icons**: Lucide React

## 설치 및 실행 가이드

### 1. 의존성 설치
```bash
npm install
```

### 2. 개발 서버 실행
```bash
npm run dev
```

### 3. 웹 브라우저 접속
[http://localhost:3000](http://localhost:3000) 으로 이동

### 4. ITEasy OpenAI API 키 설정
1. 화면의 "API Key 설정" 또는 "설정" 버튼 클릭
2. ITEasy에서 제공받은 OpenAI API 키 입력
3. 필요시 AI 모델 설정 조정 (GPT-3.5, GPT-4 등)
4. "키 검증" 버튼으로 유효성 확인
5. 설정 저장

**참고**: 환경변수로도 API 키 설정 가능 (`.env.local` 파일):
```
OPENAI_API_KEY=iteasy_openai_api_key_here
```

### 5. 사내 사용 가이드
- **프로젝트별 대화**: 각 프로젝트/업무별로 별도 대화 생성
- **제목 편집**: 사이드바에서 대화 제목을 더블클릭하여 편집
- **토큰 추적**: AI 답변의 차트 아이콘 클릭으로 사용량 확인
- **설정 최적화**: 업무 특성에 맞게 모델과 창의성 조절

## Project Structure

```
├── app/
│   ├── api/
│   │   ├── chat/route.ts      # SSE streaming API endpoint
│   │   └── validate-key/route.ts # API key validation endpoint
│   ├── components/
│   │   ├── chat/              # Chat-related components
│   │   │   ├── ChatInterface.tsx
│   │   │   ├── MessageList.tsx
│   │   │   ├── MessageItem.tsx
│   │   │   ├── InputArea.tsx
│   │   │   ├── ChatSidebar.tsx
│   │   │   └── SettingsModal.tsx
│   │   └── ui/                # Reusable UI components
│   ├── hooks/                 # Custom React hooks
│   ├── lib/                   # Utility functions
│   ├── store/                 # Zustand stores
│   │   ├── chat-store.ts      # Chat history management
│   │   └── settings-store.ts  # API key and settings
│   ├── types/                 # TypeScript type definitions
│   ├── layout.tsx
│   └── page.tsx
├── tailwind.config.ts
├── tsconfig.json
└── package.json
```

## Key Features Explained

### SSE Streaming
The app uses Server-Sent Events for real-time streaming of AI responses. The `/api/chat` endpoint leverages the Vercel AI SDK to stream tokens as they're generated by OpenAI's API.

### State Management
Zustand is used for global state management with localStorage persistence, ensuring chat history survives page refreshes.

### Markdown Support
Messages are rendered with full Markdown support including:
- Code blocks with syntax highlighting
- Tables, lists, and formatting
- GitHub Flavored Markdown (GFM)

### Performance Optimizations
- Memoized components prevent unnecessary re-renders
- Efficient message scrolling and virtualization
- Optimized Markdown parsing

## Usage

1. **Configure API Key**: 
   - First-time users will see a "Configure API Key" button
   - Click Settings in the sidebar to modify configuration anytime
   - Enter your OpenAI API key and adjust model settings

2. **Start a new chat**: Click "New Chat" in the sidebar or the welcome screen

3. **Send messages**: Type in the input area and press Enter (Shift+Enter for new lines)

4. **View responses**: AI responses stream in real-time with proper formatting

5. **Manage chats**: Switch between conversations, delete old chats

6. **Copy content**: Hover over messages to copy text or code blocks

7. **Adjust settings**: 
   - Choose between different GPT models (3.5, 4, 4-turbo, 4o)
   - Adjust temperature (creativity) from 0 (precise) to 2 (creative)
   - Set maximum tokens per response (1-4000)

## API Endpoints

- `POST /api/chat` - Streaming chat endpoint using SSE
  - Accepts: `{ messages, apiKey, model, temperature, maxTokens }`
  - Returns: SSE stream of AI response
- `POST /api/validate-key` - API key validation endpoint
  - Accepts: `{ apiKey }`
  - Returns: Validation status

## Environment Variables

- `OPENAI_API_KEY` - Your OpenAI API key (optional, can be set in-app)

## Build and Deploy

```bash
# Build for production
npm run build

# Start production server
npm start
```

## Contributing

We welcome contributions! Please follow these steps:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Make your changes
4. Test thoroughly
5. Commit your changes (`git commit -m 'Add some amazing feature'`)
6. Push to the branch (`git push origin feature/amazing-feature`)
7. Open a Pull Request

## Author

**iteasy-ops-dev**
- GitHub: [@iteasy-ops-dev](https://github.com/iteasy-ops-dev)
- Email: iteasy.ops.dev@gmail.com

## License

MIT License - feel free to use this project for your own applications.

Copyright (c) 2025 iteasy-ops-dev

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.